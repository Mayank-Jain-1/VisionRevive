# -*- coding: utf-8 -*-
"""Srgan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NFHt6Z1zxHc4ppXOzjTxxlZDHF_iAzf1
"""

import torch
from torch import nn

torch.__version__

class ConvBlock(nn.Module):
    def __init__(self,
                in_channels,
                out_channels,
                use_activation=True,
                activation='relu',
                use_batchnorm=True,
                **kwargs,
                ):
        super().__init__()
        self.use_activation = use_activation
        self.cnn = nn.Conv2d(in_channels, out_channels, bias= not use_batchnorm, **kwargs)
        self.bn = nn.BatchNorm2d(out_channels) if use_batchnorm else nn.Identity()
        self.act = (
            nn.LeakyReLU(0.2, inplace=True)
            if activation == 'relu'
            else nn.PReLU(num_parameters=out_channels)
        )

    def forward(self, x):
      return self.act(self.bn(self.cnn(x))) if self.use_activation else self.bn(self.cnn(x))

class ResidualBlock(nn.Module):
    def __init__(self,
                 in_channels,
                 ):
        super().__init__()
        self.conv1 =  ConvBlock(in_channels, in_channels, True, 'PReLU',
                                use_batchnorm=True,
                                kernel_size=3,
                                stride=1,
                                padding=1)
        self.conv2 =  ConvBlock(in_channels, in_channels, False,
                                use_batchnorm=True,
                                kernel_size=3,
                                stride=1,
                                padding=1)

    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(x)
        # print(f"Input shape = {x.shape}, output shape = {out.shape}")
        # print(f"Output after convulation = {out[0,0]}")
        return out + x

## Upsample Block

class UpsampleBlock(nn.Module):

    def __init__(self,
                 in_channels,
                 upscale_factor): # factor in 1 axis .
        super().__init__()
        self.conv = nn.Conv2d(in_channels, in_channels* upscale_factor**2, kernel_size = 3, stride = 1, padding=1)
        self.shuffle = nn.PixelShuffle(upscale_factor=upscale_factor)
        self.act = nn.PReLU(num_parameters=in_channels)

    def forward(self, x):
        # print(f"Tensor shape before Upsample = {x.shape} and after upsample it becomes = {self.shuffle(self.conv(x)).shape}")
        return self.shuffle(self.conv(x))

# Generator Class MAJOR CLASS

class Generator(nn.Module):

    def __init__(self,
                 num_channels=64,
                 num_blocks=16,
                 upscale_factor=2):
        super().__init__()
        self.initial = ConvBlock(3, num_channels,
                                 use_activation=True, activation= "PReLU",
                                 use_batchnorm=False,
                                 kernel_size=9, padding=4, stride=1)
        self.residuals = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_blocks)] )
        self.mid_conv = ConvBlock(num_channels, num_channels, use_activation=False, use_batchnorm=True, kernel_size=3 , stride=1, padding=1)
        self.upsample = nn.Sequential(UpsampleBlock(num_channels, upscale_factor), UpsampleBlock(num_channels, upscale_factor))
        self.final_conv = nn.Conv2d(in_channels=num_channels, out_channels=3, kernel_size=9, stride= 1, padding=4)

    def forward(self, x):
        initial_out = self.initial(x)
        out = self.residuals(initial_out)
        out = self.mid_conv(out) + initial_out
        out = self.upsample(out)
        out = self.final_conv(out)
        return torch.tanh(out)

# Diccriminator Major

class Discriminator(nn.Module):

    def __init__(self):
        super().__init__()
        channels = [64, 64, 128, 128, 256, 256, 512, 512]
        blocks = []
        for idx in range(len(channels)):
            blocks.append(
                ConvBlock(
                    in_channels = 3 if idx == 0 else channels[idx-1],
                    out_channels = channels[idx],
                    kernel_size = 3,
                    padding = 1,
                    stride = 1 + idx % 2,
                    use_batchnorm= False if idx == 0 else True
                )
            )
        self.conv_layers = nn.Sequential(*blocks)

        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((6,6)),
            nn.Flatten(),
            nn.Linear(512*6*6, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, 1)
        )

    def forward(self, x):
        out = self.conv_layers(x)
        out = self.classifier(out)
        return out

# testing disc
def test():
    with torch.inference_mode():
        gen = Generator()
        x = torch.rand([5,3,50,50])
        generated = gen(x)
        disc = Discriminator()
        discOutput = disc(generated)
        print(generated.shape, discOutput.shape)

if __name__ == '__main__':
    test()

