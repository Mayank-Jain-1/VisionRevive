{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kopmKZeQtprf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kJqpP6GCtuA5",
        "outputId": "c439e51b-d49f-42a8-f47c-f06d215afe0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                use_activation=True,\n",
        "                activation='relu',\n",
        "                use_batchnorm=True,\n",
        "                **kwargs,\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.use_activation = use_activation\n",
        "        self.cnn = nn.Conv2d(in_channels, out_channels, bias= not use_batchnorm, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels) if use_batchnorm else nn.Identity()\n",
        "        self.act = (\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "            if activation == 'relu'\n",
        "            else nn.PReLU(num_parameters=out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.act(self.bn(self.cnn(x))) if self.use_activation else self.bn(self.cnn(x))\n",
        "\n"
      ],
      "metadata": {
        "id": "HWMCP2ITtr9E"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing our conv block\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.inference_mode():\n",
        "    test_conv_block = ConvBlock(3, 64)\n",
        "    random_image = torch.rand([1,3,4,4])\n",
        "\n",
        "    output = test_conv_block(random_image)\n",
        "    print(output[0,:3])\n",
        "    print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0B9F9Z-0Snr",
        "outputId": "6fff4fa9-9c18-4ce7-ba05-1e31a3e855c7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.2281,  1.2712],\n",
            "         [-0.1595,  0.6668]],\n",
            "\n",
            "        [[-0.3048, -0.0020],\n",
            "         [ 0.2676,  1.2666]],\n",
            "\n",
            "        [[-0.1278,  1.3301],\n",
            "         [-0.2470,  0.5439]]])\n",
            "torch.Size([1, 64, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.conv1 =  ConvBlock(in_channels, in_channels, True, 'PReLU',\n",
        "                                use_batchnorm=True,\n",
        "                                kernel_size=3,\n",
        "                                stride=1,\n",
        "                                padding=1)\n",
        "        self.conv2 =  ConvBlock(in_channels, in_channels, False,\n",
        "                                use_batchnorm=True,\n",
        "                                kernel_size=3,\n",
        "                                stride=1,\n",
        "                                padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(x)\n",
        "        # print(f\"Input shape = {x.shape}, output shape = {out.shape}\")\n",
        "        # print(f\"Output after convulation = {out[0,0]}\")\n",
        "        return out + x\n",
        ""
      ],
      "metadata": {
        "id": "tA19SaS2xsBX"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "    test_residual = ResidualBlock(3)\n",
        "    input = torch.rand([1,3,5,5])\n",
        "    print(input[:,0])\n",
        "    output = test_residual(input)\n",
        "    print(output[:,0])\n"
      ],
      "metadata": {
        "id": "wi67i_Qit7Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Upsample Block\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 upscale_factor): # factor in 1 axis .\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels* upscale_factor**2, kernel_size = 3, stride = 1, padding=1)\n",
        "        self.shuffle = nn.PixelShuffle(upscale_factor=upscale_factor)\n",
        "        self.act = nn.PReLU(num_parameters=in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f\"Tensor shape before Upsample = {x.shape} and after upsample it becomes = {self.shuffle(self.conv(x)).shape}\")\n",
        "        return self.shuffle(self.conv(x))\n",
        "\n"
      ],
      "metadata": {
        "id": "XjY4pqJHxruy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the upsample block\n",
        "\n",
        "with torch.inference_mode():\n",
        "    upsampler = UpsampleBlock(4, 2)\n",
        "    input = torch.rand([1,4,5,5])\n",
        "    output= upsampler(input)\n",
        "    print(f\"Tensor shape before Upsample = {input.shape} and after upsample it becomes = {output.shape}\")\n",
        "    print(input[0,0])\n",
        "    print(output[0,0])"
      ],
      "metadata": {
        "id": "vvm22-I3xrsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Class MAJOR CLASS\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_channels=64,\n",
        "                 num_blocks=16,\n",
        "                 upscale_factor=2):\n",
        "        super().__init__()\n",
        "        self.initial = ConvBlock(3, num_channels,\n",
        "                                 use_activation=True, activation= \"PReLU\",\n",
        "                                 use_batchnorm=False,\n",
        "                                 kernel_size=9, padding=4, stride=1)\n",
        "        self.residuals = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_blocks)] )\n",
        "        self.mid_conv = ConvBlock(num_channels, num_channels, use_activation=False, use_batchnorm=True, kernel_size=3 , stride=1, padding=1)\n",
        "        self.upsample = nn.Sequential(UpsampleBlock(num_channels, upscale_factor), UpsampleBlock(num_channels, upscale_factor))\n",
        "        self.final_conv = nn.Conv2d(in_channels=num_channels, out_channels=3, kernel_size=9, stride= 1, padding=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        initial_out = self.initial(x)\n",
        "        out = self.residuals(initial_out)\n",
        "        out = self.mid_conv(out) + initial_out\n",
        "        out = self.upsample(out)\n",
        "        out = self.final_conv(out)\n",
        "        return torch.tanh(out)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DvT5kDsvxrp_"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing our generator\n",
        "\n",
        "with torch.inference_mode():\n",
        "    gen = Generator()\n",
        "    input = torch.rand([1,3,5,5])\n",
        "    output = gen(input)\n",
        "    print(f\"Shape of input = {input.shape}, and shape of output = {output.shape} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K23tsBKNxrnq",
        "outputId": "4b1e4a0e-8d7e-4804-862b-522dc0be64d6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input = torch.Size([1, 3, 5, 5]), and shape of output = torch.Size([1, 3, 20, 20]) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a44Z46lpxrk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RDHCDkrOxriT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}